{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path    # platform independent paths\n",
    "from IPython.display import Markdown, display\n",
    "import pandas as pd\n",
    "from nltk.probability import FreqDist    # frequency dictionary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set figure size\n",
    "plt.rcParams['figure.figsize'] = [20, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string, color=None):\n",
    "    ''' NOT MINE\n",
    "    Markdown printing from a code cell\n",
    "    Ex. printmd(\"**bold and blue**\", color=\"blue\")\n",
    "    https://stackoverflow.com/questions/23271575/printing-bold-colored-etc-text-in-ipython-qtconsole\n",
    "    '''\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_dist(some_list, min_freq = 1, exact_freq = 1, top = 0):\n",
    "    '''\n",
    "    Adding in fucntionality to FreqDist\n",
    "    Need to add in raise errors if more than one optional argument used.\n",
    "    '''\n",
    "    temp = FreqDist(some_list)\n",
    "    if (min_freq != 1):\n",
    "        temp = [(k, v) for k, v in temp.items() if v > min_freq]\n",
    "        temp.sort(key=lambda x: x[1], reverse = True)\n",
    "        return temp\n",
    "    elif (exact_freq != 1):\n",
    "        temp = [(k, v) for k, v in temp.items() if v == exact_freq]\n",
    "        return temp\n",
    "    elif (top != 0):\n",
    "        return temp.most_common(top)\n",
    "    else:\n",
    "        temp = [(k, v) for k, v in temp.items()]\n",
    "        temp.sort(key=lambda x: x[1], reverse = True)\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File locations\n",
    "file_neg = Path('../input/comments_negative.csv')\n",
    "file_pos = Path('../input/comments_positive.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into dataframes\n",
    "df_neg = pd.read_csv(file_neg)\n",
    "df_pos = pd.read_csv(file_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_neg = df_neg.sample(n=100000, random_state=1)\n",
    "#df_pos = df_pos.sample(n=100000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>author</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_link_id</th>\n",
       "      <th>parent_text</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_author</th>\n",
       "      <th>parent_controversiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0a2d2p</td>\n",
       "      <td>t1_c0a2cn1</td>\n",
       "      <td>t5_1a8ah</td>\n",
       "      <td>t3_8pr4w</td>\n",
       "      <td>Na, not really. \\n\\nI just hate islam and ever...</td>\n",
       "      <td>-2946</td>\n",
       "      <td>-2946</td>\n",
       "      <td>b34nz</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_8pr4w</td>\n",
       "      <td>What goes through the heads of you people?  Is...</td>\n",
       "      <td>459</td>\n",
       "      <td>459</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c6okok8</td>\n",
       "      <td>t1_c6oaywb</td>\n",
       "      <td>t5_2s8e9</td>\n",
       "      <td>t3_11otij</td>\n",
       "      <td>lol you're some ugly ass white dude</td>\n",
       "      <td>-2724</td>\n",
       "      <td>-2724</td>\n",
       "      <td>letmetellyouhowitis</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_11otij</td>\n",
       "      <td>This is worth noting.\\n\\nThankfully I don't.</td>\n",
       "      <td>72</td>\n",
       "      <td>72</td>\n",
       "      <td>flowen65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c3nlalf</td>\n",
       "      <td>t1_c3nijr7</td>\n",
       "      <td>t5_2qzb6</td>\n",
       "      <td>t3_p9a1v</td>\n",
       "      <td>First of off, its not true, and second off, I ...</td>\n",
       "      <td>-2132</td>\n",
       "      <td>-2132</td>\n",
       "      <td>iamwoodyharrelson</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_p9a1v</td>\n",
       "      <td>I swear this is *(allegedly)* a true story.  I...</td>\n",
       "      <td>4028</td>\n",
       "      <td>4028</td>\n",
       "      <td>AndyRooney</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c10nh8q</td>\n",
       "      <td>t1_c10nc34</td>\n",
       "      <td>t5_6</td>\n",
       "      <td>t3_djasj</td>\n",
       "      <td>Who made you reddit police? I will submit what...</td>\n",
       "      <td>-2117</td>\n",
       "      <td>-2117</td>\n",
       "      <td>JimmyJamesincorp</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_djasj</td>\n",
       "      <td>I was on my way over here to bitch and moan ab...</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>SloaneRanger</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c3nlufk</td>\n",
       "      <td>t1_c3nlcob</td>\n",
       "      <td>t5_2qzb6</td>\n",
       "      <td>t3_p9a1v</td>\n",
       "      <td>We gotta be...i consider my time valuable.</td>\n",
       "      <td>-1962</td>\n",
       "      <td>-1962</td>\n",
       "      <td>iamwoodyharrelson</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_p9a1v</td>\n",
       "      <td>Should change this AMA to AMAAR (Ask Me Anythi...</td>\n",
       "      <td>1405</td>\n",
       "      <td>1405</td>\n",
       "      <td>bersh</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   parent_id subreddit_id    link_id  \\\n",
       "0  c0a2d2p  t1_c0a2cn1     t5_1a8ah   t3_8pr4w   \n",
       "1  c6okok8  t1_c6oaywb     t5_2s8e9  t3_11otij   \n",
       "2  c3nlalf  t1_c3nijr7     t5_2qzb6   t3_p9a1v   \n",
       "3  c10nh8q  t1_c10nc34         t5_6   t3_djasj   \n",
       "4  c3nlufk  t1_c3nlcob     t5_2qzb6   t3_p9a1v   \n",
       "\n",
       "                                                text  score   ups  \\\n",
       "0  Na, not really. \\n\\nI just hate islam and ever...  -2946 -2946   \n",
       "1                lol you're some ugly ass white dude  -2724 -2724   \n",
       "2  First of off, its not true, and second off, I ...  -2132 -2132   \n",
       "3  Who made you reddit police? I will submit what...  -2117 -2117   \n",
       "4        We gotta be...i consider my time valuable.   -1962 -1962   \n",
       "\n",
       "                author  controversiality parent_link_id  \\\n",
       "0                b34nz                 0       t3_8pr4w   \n",
       "1  letmetellyouhowitis                 0      t3_11otij   \n",
       "2    iamwoodyharrelson                 0       t3_p9a1v   \n",
       "3     JimmyJamesincorp                 0       t3_djasj   \n",
       "4    iamwoodyharrelson                 0       t3_p9a1v   \n",
       "\n",
       "                                         parent_text  parent_score  \\\n",
       "0  What goes through the heads of you people?  Is...           459   \n",
       "1      This is worth noting.\\n\\nThankfully I don't.             72   \n",
       "2  I swear this is *(allegedly)* a true story.  I...          4028   \n",
       "3  I was on my way over here to bitch and moan ab...          1214   \n",
       "4  Should change this AMA to AMAAR (Ask Me Anythi...          1405   \n",
       "\n",
       "   parent_ups parent_author  parent_controversiality  \n",
       "0         459     [deleted]                        0  \n",
       "1          72      flowen65                        0  \n",
       "2        4028    AndyRooney                        0  \n",
       "3        1214  SloaneRanger                        0  \n",
       "4        1405         bersh                        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_neg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit_id</th>\n",
       "      <th>link_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>ups</th>\n",
       "      <th>author</th>\n",
       "      <th>controversiality</th>\n",
       "      <th>parent_link_id</th>\n",
       "      <th>parent_text</th>\n",
       "      <th>parent_score</th>\n",
       "      <th>parent_ups</th>\n",
       "      <th>parent_author</th>\n",
       "      <th>parent_controversiality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c092j8m</td>\n",
       "      <td>t1_c092gss</td>\n",
       "      <td>t5_2qh2p</td>\n",
       "      <td>t3_8eyy3</td>\n",
       "      <td>This isn't Twitter: try to comment on the arti...</td>\n",
       "      <td>9582</td>\n",
       "      <td>9582</td>\n",
       "      <td>nraustinii</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_8eyy3</td>\n",
       "      <td>Fucking faggot.</td>\n",
       "      <td>-7526</td>\n",
       "      <td>-7526</td>\n",
       "      <td>Glorificus</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c4imcva</td>\n",
       "      <td>t1_c4im948</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>Well, it is exactly what it sounds like. It's ...</td>\n",
       "      <td>9531</td>\n",
       "      <td>9531</td>\n",
       "      <td>Lynfect</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>Elaborate on this cum box, please.</td>\n",
       "      <td>3841</td>\n",
       "      <td>3841</td>\n",
       "      <td>eeeeevil</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c0s4nfi</td>\n",
       "      <td>t1_c0s4lje</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>t3_cf1n2</td>\n",
       "      <td>In soviet Russia, bomb disarms you!</td>\n",
       "      <td>8545</td>\n",
       "      <td>8545</td>\n",
       "      <td>CapnScumbone</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_cf1n2</td>\n",
       "      <td>I don't live in Russia anymore, and I will not...</td>\n",
       "      <td>621</td>\n",
       "      <td>621</td>\n",
       "      <td>shady8x</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c4ini33</td>\n",
       "      <td>t1_c4incln</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>\"runin for senitur! #YOLO!\"</td>\n",
       "      <td>7430</td>\n",
       "      <td>7430</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>This just made me realize that future presiden...</td>\n",
       "      <td>4651</td>\n",
       "      <td>4651</td>\n",
       "      <td>drspg99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c4imgel</td>\n",
       "      <td>t1_c4ima2e</td>\n",
       "      <td>t5_2qh1i</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>You step motherfucker.</td>\n",
       "      <td>7173</td>\n",
       "      <td>7173</td>\n",
       "      <td>jbg89</td>\n",
       "      <td>0</td>\n",
       "      <td>t3_t0ynr</td>\n",
       "      <td>I have sex with my step mom when my dad isn't ...</td>\n",
       "      <td>4251</td>\n",
       "      <td>4251</td>\n",
       "      <td>audir8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   parent_id subreddit_id   link_id  \\\n",
       "0  c092j8m  t1_c092gss     t5_2qh2p  t3_8eyy3   \n",
       "1  c4imcva  t1_c4im948     t5_2qh1i  t3_t0ynr   \n",
       "2  c0s4nfi  t1_c0s4lje     t5_2qh1i  t3_cf1n2   \n",
       "3  c4ini33  t1_c4incln     t5_2qh1i  t3_t0ynr   \n",
       "4  c4imgel  t1_c4ima2e     t5_2qh1i  t3_t0ynr   \n",
       "\n",
       "                                                text  score   ups  \\\n",
       "0  This isn't Twitter: try to comment on the arti...   9582  9582   \n",
       "1  Well, it is exactly what it sounds like. It's ...   9531  9531   \n",
       "2                In soviet Russia, bomb disarms you!   8545  8545   \n",
       "3                        \"runin for senitur! #YOLO!\"   7430  7430   \n",
       "4                             You step motherfucker.   7173  7173   \n",
       "\n",
       "         author  controversiality parent_link_id  \\\n",
       "0    nraustinii                 0       t3_8eyy3   \n",
       "1       Lynfect                 0       t3_t0ynr   \n",
       "2  CapnScumbone                 0       t3_cf1n2   \n",
       "3     [deleted]                 0       t3_t0ynr   \n",
       "4         jbg89                 0       t3_t0ynr   \n",
       "\n",
       "                                         parent_text  parent_score  \\\n",
       "0                                    Fucking faggot.         -7526   \n",
       "1                 Elaborate on this cum box, please.          3841   \n",
       "2  I don't live in Russia anymore, and I will not...           621   \n",
       "3  This just made me realize that future presiden...          4651   \n",
       "4  I have sex with my step mom when my dad isn't ...          4251   \n",
       "\n",
       "   parent_ups parent_author  parent_controversiality  \n",
       "0       -7526    Glorificus                        0  \n",
       "1        3841      eeeeevil                        0  \n",
       "2         621       shady8x                        0  \n",
       "3        4651       drspg99                        0  \n",
       "4        4251        audir8                        0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine positive and negative comment data sets and exclude those without text or parent text fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDF = pd.concat([df_pos,df_neg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalDF = totalDF[totalDF['text'].notnull()]\n",
    "totalDF = totalDF[totalDF['parent_text'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = 5\n",
    "df_neg = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bin scores to give < -1000, < -100, -100 < 100, >100, >1000 as our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (totalDF['score'] < -1000) ,\n",
    "    (totalDF['score'] > -1000) & (totalDF['score'] < -100),\n",
    "    (totalDF['score'] > -100) & (totalDF['score'] < 100),\n",
    "    (totalDF['score'] > 100) & (totalDF['score'] < 1000),\n",
    "    (totalDF['score'] > 1000)]\n",
    "choices = [-2, -1, 0,1,2]\n",
    "totalDF['category'] = np.select(conditions, choices, default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split dataset in half to allow test and training, due to using transfer learning from BERT interesting to assess whether training/fine tuning bert on a small subset of the data is effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(totalDF, totalDF[\"category\"], test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "install bert libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert\r\n",
      "  Downloading https://files.pythonhosted.org/packages/e8/e6/55ed98ef52b168a38192da1aff7265c640f214009790220664ee3b4cb52a/bert-2.2.0.tar.gz\r\n",
      "Collecting erlastic (from bert)\r\n",
      "  Downloading https://files.pythonhosted.org/packages/f3/30/f40d99fe35c38c2e0415b1e746c89569f2483e64ef65d054b9f0f382f234/erlastic-2.0.0.tar.gz\r\n",
      "Building wheels for collected packages: bert, erlastic\r\n",
      "  Building wheel for bert (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for bert: filename=bert-2.2.0-cp36-none-any.whl size=3755 sha256=683c78f2caa92810242604d0eaf04e920ec053432b4a072b720d3401d372195e\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/fe/71/b7/941459453bd38e5d97a8c886361dee19325e9933c9cf88ad46\r\n",
      "  Building wheel for erlastic (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for erlastic: filename=erlastic-2.0.0-cp36-none-any.whl size=6789 sha256=8b726ca8a350ba3f1e02ec5d166fcac3a890764c4422eb73705c8b0054c116ed\r\n",
      "  Stored in directory: /tmp/.cache/pip/wheels/02/62/46/93c713a5f061aeeb4f16eb6bf5ee798816e6ddda70faa78e69\r\n",
      "Successfully built bert erlastic\r\n",
      "Installing collected packages: erlastic, bert\r\n",
      "Successfully installed bert-2.2.0 erlastic-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "!pip install bert\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-tensorflow\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\r\n",
      "\u001b[K     |████████████████████████████████| 71kB 2.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from bert-tensorflow) (1.12.0)\r\n",
      "Installing collected packages: bert-tensorflow\r\n",
      "Successfully installed bert-tensorflow-1.0.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Params for bert model and tokenization\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample training data to a smaller subset of 100k reddit posts to allow quicker fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train =  X_train.sample(n=500000, random_state=1)\n",
    "#X_train =  X_train.sample(n=100000, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of               id   parent_id subreddit_id    link_id  \\\n",
       "659856   c1wdza6  t1_c1wdmaf     t5_2qh0u   t3_hlni7   \n",
       "1452960  co8401v  t1_co81w7v     t5_2qt55  t3_2uez6o   \n",
       "1082665  c1mqnbl  t1_c1mqffr     t5_2qh1i   t3_gd6fq   \n",
       "1880202  c67ltdn  t1_c67llif     t5_2qhwp   t3_ztltg   \n",
       "1595864  c11pmxe  t1_c11pjie         t5_6   t3_doe17   \n",
       "518495   cnx8c62  t1_cnx6ge1     t5_2qh1i  t3_2ta2t2   \n",
       "1813614  cpf40xj  t1_cpezlcb     t5_2va9w  t3_2z1gc4   \n",
       "853719   c07hgba  t1_c07hfii     t5_2qh0s   t3_7v013   \n",
       "1340875  co8je8w  t1_co8fy43     t5_2qh1i  t3_2ug029   \n",
       "1813894  c6j2dxy  t1_c6j2b0o     t5_2qh03  t3_113193   \n",
       "806676   c695hup  t1_c695gec     t5_2qh33   t3_zz46f   \n",
       "1917869  c47hfx4  t1_c47gdkj     t5_2rjz2   t3_roo4f   \n",
       "1912055  c4ogdck  t1_c4ofkfu     t5_2qh1i   t3_to521   \n",
       "656368   c4af2km  t1_c4aevcq     t5_2qh1e   t3_s16lc   \n",
       "930642   c5a8dzt  t1_c5a7qif     t5_2qhx4   t3_w4k0r   \n",
       "1928782  c5mm3mf  t1_c5mlmkw     t5_2qhx4   t3_xidok   \n",
       "997404   c420gkq  t1_c4205wf     t5_2cneq   t3_r0vt6   \n",
       "774243   c5ucf8i  t1_c5uc7de     t5_2qqjc   t3_yceij   \n",
       "1416705  c6frmgn  t1_c6frbnt     t5_2qh1e  t3_10q1up   \n",
       "487779   c0wtbe1  t1_c0wt3qj     t5_2qh1i   t3_d1a5w   \n",
       "1213530  c6a38sn  t1_c6a2wdu     t5_2qh1i  t3_103944   \n",
       "1580947  c17h452  t1_c17gvbl         t5_6   t3_ee8qs   \n",
       "767308   c5psq1t  t1_c5pnfhm     t5_2qh16   t3_xu7nf   \n",
       "204411   c5idchn  t1_c5id4r0     t5_2qh1i   t3_x1cw6   \n",
       "1358427  c24dfx5  t1_c24cm5r     t5_2qh1i   t3_ijy0e   \n",
       "1488655  cpibhio  t1_cpi2i8y     t5_2qh1i  t3_2zdr2k   \n",
       "260263   coks2a5  t1_cokorw1     t5_2qh1o  t3_2vspj8   \n",
       "1176602  c4alrc7  t1_c4alqix     t5_2qh03   t3_s2mjh   \n",
       "679415   c6i7lqn  t1_c6i6g3t     t5_2qt55  t3_1107q2   \n",
       "1762151  c47y5ev  t1_c47xlzr     t5_2qh16   t3_rqmh8   \n",
       "...          ...         ...          ...        ...   \n",
       "679694   cnnt38y  t1_cnnq9tv     t5_2qh1i  t3_2satoh   \n",
       "543787   cp1c3xz  t1_cp1amlj     t5_2qh33  t3_2xkvte   \n",
       "1697223  c0nkdom  t1_c0nkc3r     t5_2qh0u   t3_bmv71   \n",
       "466231   com8mln  t1_com7rxu     t5_2sljg  t3_2vzcpx   \n",
       "228633   c4iztue  t1_c4izb6y     t5_2qo4s   t3_t2i1k   \n",
       "666322   c6qb2kw  t1_c6qami8     t5_2qh1i  t3_11wlff   \n",
       "716681   c54todh  t1_c54s1z6     t5_2ss5b   t3_vi4pf   \n",
       "1365094  c5oiver  t1_c5oifnh     t5_2qh61   t3_xpok5   \n",
       "939850   c5haq76  t1_c5hanoe     t5_2qpp6   t3_wxg2i   \n",
       "247796   c4t9dx1  t1_c4t9bwg     t5_2qh1i   t3_u8kjy   \n",
       "834019   c11wm54  t1_c11wlch     t5_2r5vt   t3_dpad6   \n",
       "1729716  c47amhl  t1_c478uvr     t5_2qi58   t3_rno1w   \n",
       "1006961  c149525  t1_c1494jj     t5_2qh61   t3_e06py   \n",
       "419181   c5z1yzv  t1_c5z1d3n     t5_2qh0u   t3_yurib   \n",
       "97121    cnsh3rt  t1_cnsh0cd     t5_2qh0u  t3_2srexw   \n",
       "1557218  cpf6wgy  t1_cpf502d     t5_2usfk  t3_2z2atd   \n",
       "1241074  cnqqpfw  t1_cnqqcv2     t5_2qjvn  t3_2skrtf   \n",
       "387323   c1uotc1  t1_c1uok10     t5_2qh13   t3_he03z   \n",
       "732684   cph6j5y  t1_cph59ct     t5_2x2oy  t3_2z91yx   \n",
       "739248   c6r76y0  t1_c6r6akl     t5_2qh1i  t3_1203ve   \n",
       "539      co8r2co  t1_co8qxyl     t5_2qh1i  t3_2uibgu   \n",
       "660262   c5u4db5  t1_c5u474z     t5_2qmg3   t3_ybq2g   \n",
       "1556723  c0vl9pt  t1_c0vl0fl     t5_2cneq   t3_cvilu   \n",
       "1587934  c4n1fzm  t1_c4n0vsr     t5_2qh0u   t3_tis6w   \n",
       "1197691  c3wqoze  t1_c3wqemy     t5_2qh16   t3_qcwu7   \n",
       "1690025  c4yihw0  t1_c4yibzn     t5_2qh61   t3_utuxo   \n",
       "1301748  c4gm8is  t1_c4glior     t5_2qho4   t3_srtne   \n",
       "1625203  co9da4o  t1_co9ahea     t5_2qh1e  t3_2uk5qv   \n",
       "318252   cncvt8l  t1_cncosno     t5_33x33  t3_2r5j6l   \n",
       "1232720  c4ex01y  t1_c4ewr59     t5_2qh03   t3_sl7qp   \n",
       "\n",
       "                                                      text  score   ups  \\\n",
       "659856   It's alright.  [The internet has your back.](h...    162   162   \n",
       "1452960  But then no one will criticize my browser pref...     85    85   \n",
       "1082665  I don't want to argue about this, because it's...    109   109   \n",
       "1880202  Do you seriously need DVD playback on your Wii...     -7    -7   \n",
       "1595864                   I think it's just implied there.     79    79   \n",
       "518495   I do that *without* Ambien.\\n\\n\\n\\nEdit: Just ...    194   194   \n",
       "1813614  Last thing cringepics needs is more pics of text.     -7    -7   \n",
       "853719   I would think that your kids health would be r...    -11   -11   \n",
       "1340875  &gt;Also, you could hear the whole city that w...     91    91   \n",
       "1813894  I just hate the morons that populate this subr...     -7    -7   \n",
       "806676                                   Welcome to Reddit    -12   -12   \n",
       "1917869  You can't really be nitpicky when the actress ...     68    68   \n",
       "1912055  Sorry to break it to you but they don't :/ Mos...     -7    -7   \n",
       "656368   You're saying, \"It's very clearly a laptop\" wh...    -13   -13   \n",
       "930642                                  did he get swole?     123   123   \n",
       "1928782  You're right, but the fact is that she will ex...     68    68   \n",
       "997404   That, along with a general lack of intellectua...    117   117   \n",
       "774243   In defense of your roommate, if you don't know...    143   143   \n",
       "1416705      I gave you an upvote because fuck downvoters.     -8    -8   \n",
       "487779   you piece of shit tax payer leech...too lazy t...    -16   -16   \n",
       "1213530  But would he WANT to?  That story was a whole ...     99    99   \n",
       "1580947   Is \"Hitler and Stalin\" a powerful single entity?     80    80   \n",
       "767308   John Gruber is a typical apple fanboy.  Brags ...    -12   -12   \n",
       "204411     The Quebecois are disgusted with your comments!    379   379   \n",
       "1358427                  The words are \"livin' the dream\".     90    90   \n",
       "1488655                   Why ? Because he's not racist ?      -8    -8   \n",
       "260263   None unless they're service animals. Sounds li...    -22   -22   \n",
       "1176602                       Looking For Raid, my friend!    102   102   \n",
       "679415   There goes Tony again with another backflip ae...    158   158   \n",
       "1762151  It's a good thing his username is InverseX ins...     73    73   \n",
       "...                                                    ...    ...   ...   \n",
       "679694   For real! My tattoos look so good but nobody e...    158   158   \n",
       "543787           Could you tell us your Instagram username    -15   -15   \n",
       "1697223                       Burden of proof isn't on me.     -7    -7   \n",
       "466231   \"Why do people...?\"\\n\\nBecause people are idiots.    210   210   \n",
       "228633   Yeah, it's a little unfair but still too good ...    -23   -23   \n",
       "666322                                  why would you lie?    160   160   \n",
       "716681   No, they don't, they just think that the effec...    -13   -13   \n",
       "1365094  I once saw Maria Ozawa get raped, eaten, raped...     90    90   \n",
       "939850   &gt; I think this is just the result of some l...    -11   -11   \n",
       "247796                       Oh. Well. That's unfortunate.    333   333   \n",
       "834019   all of the above is how i describe myself, ran...    -12   -12   \n",
       "1729716                                 PURRR I AM A TIGER     74    74   \n",
       "1006961  Maybe the drunk bro had PTSD and just came bac...    116   116   \n",
       "419181                        http://i.imgur.com/L7R1p.jpg    228   228   \n",
       "97121       But it's not gay because he's only pretending.    611   611   \n",
       "1557218  Yeah I agree but I was just clarifying for his...     -8    -8   \n",
       "1241074  No he isn't any of that. He had a fight with o...     -9    -9   \n",
       "387323          &gt;I am an **idiot** and I dont get this.    -18   -18   \n",
       "732684   Wrong. Becuase if he isn't tailgating me then ...    -12   -12   \n",
       "739248   I completely agree. It's a total waste to get ...    148   148   \n",
       "539                     anything less would be uncivilized   3796  3796   \n",
       "660262   FACT: NONE OF THOSE PLAYERS WILL FINISH THE SE...    162   162   \n",
       "1556723  It was done by a group called \"anonymous\" and ...     -8    -8   \n",
       "1587934                                     Ginga *please*     80    80   \n",
       "1197691                            Upvoted for awesome pun     -9    -9   \n",
       "1690025  No, he just had some extra keys hanging on the...     76    76   \n",
       "1301748  &gt; What I am sure of is that I don't want fa...     -9    -9   \n",
       "1625203  You dont get it I guess. The point is that peo...     -7    -7   \n",
       "318252                  damn it feels good to be a gangsta    279   279   \n",
       "1232720  You probably swallowed it in your sleep. Don't...     98    98   \n",
       "\n",
       "                     author  controversiality parent_link_id  \\\n",
       "659856            [deleted]                 0       t3_hlni7   \n",
       "1452960         SillyPickle                 0      t3_2uez6o   \n",
       "1082665            ironflag                 0       t3_gd6fq   \n",
       "1880202              Horong                 0       t3_ztltg   \n",
       "1595864             tomrhod                 0       t3_doe17   \n",
       "518495          Beard_smith                 0      t3_2ta2t2   \n",
       "1813614      AdolfHitlerAMA                 0      t3_2z1gc4   \n",
       "853719              adaminc                 0       t3_7v013   \n",
       "1340875              yamsx1                 0      t3_2ug029   \n",
       "1813894           [deleted]                 0      t3_113193   \n",
       "806676            MagoLopez                 0       t3_zz46f   \n",
       "1917869           [deleted]                 0       t3_roo4f   \n",
       "1912055          TheOldBean                 0       t3_to521   \n",
       "656368               Hight5                 0       t3_s16lc   \n",
       "930642              zerobpm                 0       t3_w4k0r   \n",
       "1928782           Magnusson                 0       t3_xidok   \n",
       "997404                Detry                 0       t3_r0vt6   \n",
       "774243           yoda133113                 0       t3_yceij   \n",
       "1416705     Fuck_Downvoters                 0      t3_10q1up   \n",
       "487779             mikepunk                 0       t3_d1a5w   \n",
       "1213530           alphemale                 0      t3_103944   \n",
       "1580947       alphasquadron                 0       t3_ee8qs   \n",
       "767308             mrkite77                 0       t3_xu7nf   \n",
       "204411           Apostolate                 0       t3_x1cw6   \n",
       "1358427       analimpaction                 0       t3_ijy0e   \n",
       "1488655        BimbelMarley                 0      t3_2zdr2k   \n",
       "260263     expecto-patronum                 0      t3_2vspj8   \n",
       "1176602        Smoochiekins                 0       t3_s2mjh   \n",
       "679415                Im_11                 0      t3_1107q2   \n",
       "1762151           [deleted]                 0       t3_rqmh8   \n",
       "...                     ...               ...            ...   \n",
       "679694      lickthecowhappy                 0      t3_2satoh   \n",
       "543787             rednat16                 0      t3_2xkvte   \n",
       "1697223          A_Nihilist                 0       t3_bmv71   \n",
       "466231                 MTL9                 0      t3_2vzcpx   \n",
       "228633                katzm                 0       t3_t2i1k   \n",
       "666322   I_Just_Queefed_AMA                 0      t3_11wlff   \n",
       "716681             Borgcube                 0       t3_vi4pf   \n",
       "1365094         1gnominious                 0       t3_xpok5   \n",
       "939850           ZvG_Bonjwa                 0       t3_wxg2i   \n",
       "247796                  R99                 0       t3_u8kjy   \n",
       "834019             forrealz                 0       t3_dpad6   \n",
       "1729716           jpalmer22                 0       t3_rno1w   \n",
       "1006961           cptncrnch                 0       t3_e06py   \n",
       "419181            [deleted]                 0       t3_yurib   \n",
       "97121             M5Phalanx                 0      t3_2srexw   \n",
       "1557218     alpha_armadillo                 0      t3_2z2atd   \n",
       "1241074           KalSkotos                 0      t3_2skrtf   \n",
       "387323            [deleted]                 0       t3_he03z   \n",
       "732684             RedxEyez                 0      t3_2z91yx   \n",
       "739248              Ellimis                 0      t3_1203ve   \n",
       "539               lozergeek                 0      t3_2uibgu   \n",
       "660262            [deleted]                 0       t3_ybq2g   \n",
       "1556723             R-Legit                 0       t3_cvilu   \n",
       "1587934           [deleted]                 0       t3_tis6w   \n",
       "1197691         RandomRobot                 0       t3_qcwu7   \n",
       "1690025                 sFe                 0       t3_utuxo   \n",
       "1301748     NoMoreNicksLeft                 0       t3_srtne   \n",
       "1625203     fukkyouropinion                 0      t3_2uk5qv   \n",
       "318252             Leadback                 0      t3_2r5j6l   \n",
       "1232720        faultydesign                 0       t3_sl7qp   \n",
       "\n",
       "                                               parent_text  parent_score  \\\n",
       "659856   I was thinking the same thing and I thought to...           137   \n",
       "1452960  There's some irony in having PS on your launch...           224   \n",
       "1082665  Except for the fact that while it may take a f...             9   \n",
       "1880202  Haven't seen the answer to this yet. If I put ...            18   \n",
       "1595864  &gt; Say hello to Guantanamo for us!\\n\\nAnd be...           229   \n",
       "518495   Ambien also causes some people to sleepwalk an...          1306   \n",
       "1813614  Oh god, we could supply this sub with weeks of...            28   \n",
       "853719   I'm a smoker, and the only thing better than s...             9   \n",
       "1340875  Saw 9/11 from my rooftop in Jersey City. It's ...           111   \n",
       "1813894                           You, sir, love to argue.             3   \n",
       "806676   I third this. I'm legitimately bothered by thi...            12   \n",
       "1917869  I thought Daenerys' eye contact with the drago...           151   \n",
       "1912055  Just Paris (the rest of France is pretty mello...             1   \n",
       "656368    I have no idea what you're even responding to...             6   \n",
       "930642   Not necessarily at the gym but my friends were...           127   \n",
       "1928782  Still sounds like a double standard to me. Cal...           758   \n",
       "997404   The right wingers are good, very good, at misi...           146   \n",
       "774243   My college roommate had a side gig working sec...           254   \n",
       "1416705   Then help him... We are not your personal army.            -21   \n",
       "487779   I was a horrible student in high school, and i...            23   \n",
       "1213530  He could probably guilt her into nightly handj...           486   \n",
       "1580947  I think Hitler and Stalin has won, multiple ti...            89   \n",
       "767308   To quote John Gruber: I’m sure this will get j...            14   \n",
       "204411                                       Close enough.          1690   \n",
       "1358427  If you're cheating on your underage girlfriend...           208   \n",
       "1488655  A guy who walks his dog in the neighborhood on...            93   \n",
       "260263   What flights allow dogs in the seats? Are they...           182   \n",
       "1176602  You know how it would be. :&lt; We'd roll a ne...           519   \n",
       "679415   the lack of enthusiasm from the rest of the pe...           169   \n",
       "1762151  Please do cite this. Among other things, citin...           372   \n",
       "...                                                    ...           ...   \n",
       "679694   I can almost burn when it's raining but the co...          2774   \n",
       "543787   You're totally right! But I don't feel like do...           146   \n",
       "1697223  Did you or did you not check them out for your...             2   \n",
       "466231   Why do people make social media accounts using...           177   \n",
       "228633   They showed his family showing up a few minute...            24   \n",
       "666322       I'm not going to lie that's pretty awesome...            74   \n",
       "716681   I will never understand why so many people on ...            61   \n",
       "1365094  Just out of curiosity.... What would happen if...           295   \n",
       "939850   Well I'm definitely not suggesting everyone bo...            15   \n",
       "247796   nah. We danced in front of all our english tea...           476   \n",
       "834019   Yes. That isn't even a correct usage of the wo...            21   \n",
       "1729716                                    ARR IM A PIRATE           275   \n",
       "1006961                *terrorist threat* is what i heard.            60   \n",
       "419181   many of these girls actually look like a **gre...            -9   \n",
       "97121     He's small and lets the alpha have sex with him.           300   \n",
       "1557218  Yeah but it looks like he maxed his King and h...             8   \n",
       "1241074  He's a racist, sexist, anti Semite who beats h...            14   \n",
       "387323   I dont understand this about Christianity - ch...           145   \n",
       "732684   He doesn't have to be tailgating you for you t...             7   \n",
       "739248   Her reaction was very rude, but...\\n\\nDon't bu...           347   \n",
       "539      Rinse my toothbrush, put toothpaste on it, the...          4409   \n",
       "660262   BRING IT ON!  OH, TOO LATE, VICK, DESEAN, MCCO...            41   \n",
       "1556723  Blah.  The original use of the quote might hav...             5   \n",
       "1587934  Hey! Only a ginger can call another ginger gin...           145   \n",
       "1197691                    Yes, I *do* excel at MS Office.            29   \n",
       "1690025  Whoa whoa whoa, stop right there. That is real...            82   \n",
       "1301748  I'm not sure that any group wants to \"de-relig...             9   \n",
       "1625203  To be honest, I don't see how it's that much w...           175   \n",
       "318252                          nigga's name is schneider?           812   \n",
       "1232720  When I was playing Skyrim a while ago I notice...           112   \n",
       "\n",
       "         parent_ups         parent_author  parent_controversiality  category  \n",
       "659856          137             10thBeard                        0         1  \n",
       "1452960         224          gravityplanx                        0         0  \n",
       "1082665           9              avamarie                        0         1  \n",
       "1880202          18      DetachableMonkey                        0         0  \n",
       "1595864         229             [deleted]                        0         0  \n",
       "518495         1306      Stabmaster_Arson                        0         1  \n",
       "1813614          28               Nuhjeea                        0         0  \n",
       "853719            9             [deleted]                        0         0  \n",
       "1340875         111               69sucka                        0         0  \n",
       "1813894           3              Comquter                        0         0  \n",
       "806676           12         vicschuldiner                        0         0  \n",
       "1917869         151                 BJabs                        0         0  \n",
       "1912055           1                 SG-17                        0         0  \n",
       "656368            6          Binary_Input                        0         0  \n",
       "930642          127               rjc999x                        0         1  \n",
       "1928782         758             [deleted]                        0         0  \n",
       "997404          146            njmaverick                        0         1  \n",
       "774243          254      chet_lemon_party                        0         1  \n",
       "1416705         -21           playdoepete                        0         0  \n",
       "487779           23             [deleted]                        0         0  \n",
       "1213530         486                stufff                        0         0  \n",
       "1580947          89       playingwithfire                        0         0  \n",
       "767308           14            reticulate                        0         0  \n",
       "204411         1690      JustALittleWeird                        0         1  \n",
       "1358427         208            Caedus_Vao                        0         0  \n",
       "1488655          93             Back2Bach                        0         0  \n",
       "260263          182               Jenky85                        0         0  \n",
       "1176602         519          SonicFlash01                        0         1  \n",
       "679415          169         thedaveoflife                        0         1  \n",
       "1762151         372               Procris                        0         0  \n",
       "...             ...                   ...                      ...       ...  \n",
       "679694         2774  CallMeSnuffaluffagus                        0         1  \n",
       "543787          146              killla_k                        0         0  \n",
       "1697223           2             [deleted]                        0         0  \n",
       "466231          177          RidleyScotch                        0         1  \n",
       "228633           24           Starguy2012                        0         0  \n",
       "666322           74          cntspel4lief                        0         1  \n",
       "716681           61             numb3rb0y                        0         0  \n",
       "1365094         295         josephanthony                        0         0  \n",
       "939850           15             samrolken                        0         0  \n",
       "247796          476             [deleted]                        0         1  \n",
       "834019           21         Ifyoureadthis                        0         0  \n",
       "1729716         275                Schnix                        0         0  \n",
       "1006961          60                 sfade                        0         1  \n",
       "419181           -9              kenn4000                        0         1  \n",
       "97121           300             Ha_window                        0         1  \n",
       "1557218           8            Manburpigg                        0         0  \n",
       "1241074          14         annainpajamas                        0         0  \n",
       "387323          145             enterence                        0         0  \n",
       "732684            7   Another_Random_User                        0         0  \n",
       "739248          347        Weed_O_Whirler                        0         1  \n",
       "539            4409              Ledzebra                        0         2  \n",
       "660262           41             Immynimmy                        0         1  \n",
       "1556723           5            deathdonut                        0         0  \n",
       "1587934         145             [deleted]                        0         0  \n",
       "1197691          29           rabbidpanda                        0         0  \n",
       "1690025          82                 keesh                        0         0  \n",
       "1301748           9              strugglz                        0         0  \n",
       "1625203         175        ihave_problems                        0         0  \n",
       "318252          812           HandJobSwag                        0         1  \n",
       "1232720         112               SirDoug                        0         0  \n",
       "\n",
       "[500000 rows x 16 columns]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_seq_length = 32\n",
    "max_seq_length = 18\n",
    "\n",
    "# Create datasets (Only take up to max_seq_length words for memory)\n",
    "train_text = X_train['text'].tolist()\n",
    "train_text = [' '.join(t.split()[0:max_seq_length]) for t in train_text]\n",
    "train_text = np.array(train_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "\n",
    "#train_label = totalDF['score'].tolist()\n",
    "train_label = X_train['category'].tolist()\n",
    "\n",
    "train2_text = X_train['parent_text'].tolist()\n",
    "train2_text = [' '.join(t.split()[0:max_seq_length]) for t in train2_text]\n",
    "train2_text = np.array(train2_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "test_text = X_test['text'].tolist()\n",
    "test_text = [' '.join(t.split()[0:max_seq_length]) for t in test_text]\n",
    "test_text = np.array(test_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "test2_text = X_test['parent_text'].tolist()\n",
    "test2_text = [' '.join(t.split()[0:max_seq_length]) for t in test2_text]\n",
    "test2_text = np.array(test2_text, dtype=object)[:, np.newaxis]\n",
    "\n",
    "test_label =  X_test['category'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what label bins are represented in the test and train data (sometimes doesn't capture any -2 scores (<-1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -1,  0,  1,  2])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2, -1,  0,  1,  2])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_label = totalDF[.tolist()\n",
    "# train_text = totalDF['text'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a modified version of Jacob Zweig's code for using bert with tensorflow https://towardsdatascience.com/bert-in-keras-with-tensorflow-hub-76bcbc9417b.\n",
    "\n",
    "Modifications have been made to add parent_text and the text of the reddit post itself as inputs rather than just one text feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf3d1402ace443199744cb48ccfe706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=500000, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b66066dc78d4e00abf9daf0b6557f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=500000, style=ProgressS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples\n",
    "\n",
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "\n",
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_text, train_label)\n",
    "train2_examples = convert_text_to_examples(train2_text, train_label)\n",
    "test_examples = convert_text_to_examples(test_text, test_label)\n",
    "test2_examples = convert_text_to_examples(test2_text, test_label)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
    "\n",
    "(train2_input_ids, train2_input_masks, train2_segment_ids, train_labels \n",
    ") = convert_examples_to_features(tokenizer, train2_examples, max_seq_length=max_seq_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have  tokenized masks and segment ids for bert layer to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one hot encode training labels to use with 5 wide NN output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "label_binarizer = sklearn.preprocessing.LabelBinarizer()\n",
    "label_binarizer.fit([-2,-1,0,1,2])\n",
    "train_label_bak = train_labels\n",
    "train_labels = label_binarizer.transform(train_labels)\n",
    "#test_labels = label_binarizer.transform(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_label_bak,10, facecolor='blue', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_labels = pd.get_dummies(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create NN model using Bert once again this was taken from Jacob Zweig's notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLayer(tf.keras.layers.Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_fine_tune_layers=10,\n",
    "        pooling=\"first\",\n",
    "        bert_path=\"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\",\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        self.pooling = pooling\n",
    "        self.bert_path = bert_path\n",
    "        if self.pooling not in [\"first\", \"mean\"]:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            self.bert_path, trainable=self.trainable, name=f\"{self.name}_module\"\n",
    "        )\n",
    "\n",
    "        # Remove unused layers\n",
    "        trainable_vars = self.bert.variables\n",
    "        if self.pooling == \"first\":\n",
    "            trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "            trainable_layers = [\"pooler/dense\"]\n",
    "\n",
    "        elif self.pooling == \"mean\":\n",
    "            trainable_vars = [\n",
    "                var\n",
    "                for var in trainable_vars\n",
    "                if not \"/cls/\" in var.name and not \"/pooler/\" in var.name\n",
    "            ]\n",
    "            trainable_layers = []\n",
    "        else:\n",
    "            raise NameError(\n",
    "                f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\"\n",
    "            )\n",
    "\n",
    "        # Select how many layers to fine tune\n",
    "        for i in range(self.n_fine_tune_layers):\n",
    "            trainable_layers.append(f\"encoder/layer_{str(11 - i)}\")\n",
    "\n",
    "        # Update trainable vars to contain only the specified layers\n",
    "        trainable_vars = [\n",
    "            var\n",
    "            for var in trainable_vars\n",
    "            if any([l in var.name for l in trainable_layers])\n",
    "        ]\n",
    "\n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "\n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        if self.pooling == \"first\":\n",
    "            pooled = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"pooled_output\"\n",
    "            ]\n",
    "        elif self.pooling == \"mean\":\n",
    "            result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "                \"sequence_output\"\n",
    "            ]\n",
    "\n",
    "            mul_mask = lambda x, m: x * tf.expand_dims(m, axis=-1)\n",
    "            masked_reduce_mean = lambda x, m: tf.reduce_sum(mul_mask(x, m), axis=1) / (\n",
    "                    tf.reduce_sum(m, axis=1, keepdims=True) + 1e-10)\n",
    "            input_mask = tf.cast(input_mask, tf.float32)\n",
    "            pooled = masked_reduce_mean(result, input_mask)\n",
    "        else:\n",
    "            raise NameError(f\"Undefined pooling type (must be either first or mean, but is {self.pooling}\")\n",
    "\n",
    "        return pooled\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metrics to measure during runtime of keras\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "# Build model\n",
    "def build_model(max_seq_length): \n",
    "    # add width to acommodate combined parent_text and text features\n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n",
    "    #dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "    dense = tf.keras.layers.Dense(42, activation='relu')(bert_output)\n",
    "    #pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    pred = tf.keras.layers.Dense(5, activation='softmax')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=bert_inputs, outputs=pred)\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine ids masks and segment ids into one array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train3_input_ids = np.hstack((train_input_ids, train2_input_ids))\n",
    "train3_input_masks = np.hstack((train_input_masks, train2_input_masks))\n",
    "train3_segment_ids = np.hstack((train_segment_ids, train2_segment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Bert model with combined parent_text and text input parameters as our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer (BertLayer)          (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 42)           32298       bert_layer[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5)            215         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 110,137,403\n",
      "Trainable params: 21,886,721\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "393184/500000 [======================>.......] - ETA: 4:01 - loss: 0.6736 - f1: 0.6982"
     ]
    }
   ],
   "source": [
    "model = build_model(max_seq_length)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model.fit(\n",
    "    [train3_input_ids, train3_input_masks, train3_segment_ids], \n",
    "    train_labels,\n",
    "   # validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=1,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('BertModel.h5')\n",
    "# pre_save_preds = model.predict([test3_input_ids[0:100], \n",
    "#                                 test3_input_masks[0:100], \n",
    "#                                 test3_segment_ids[0:100]]\n",
    "#                               ) # predictions before we clear and reload model\n",
    "\n",
    "# # Clear and load model\n",
    "# model = None\n",
    "# model = build_model(max_seq_length)\n",
    "# initialize_vars(sess)\n",
    "# model.load_weights('BertModel.h5')\n",
    "\n",
    "#post_save_preds = model.predict([test3_input_ids[0:100], \n",
    "                             #   test3_input_masks[0:100], \n",
    "                           #     test3_segment_ids[0:100]]\n",
    "                         #     ) # predictions after we clear and reload model\n",
    "#all(pre_save_preds == post_save_preds) # Are they the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assess the metrics of training error using F1 score, we will check later how well this translates against the full set of test data we split out previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 737s 1ms/sample - loss: 0.6698 - f1: 0.6991\n",
      "f1: 69.91%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate( [train3_input_ids, train3_input_masks, train3_segment_ids], \n",
    "    train_labels, \n",
    "                        verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/sample - loss: 19.2060 - f1: 0.0000e+00\n",
      "Very Negative Class performance f1: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# check class performance for very negative posts\n",
    "VNeg = train_labels[:,0] == 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "scores = model.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n",
    "    train_labels[VNeg], \n",
    "                        verbose=1)\n",
    "print(\"Very Negative Class performance %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4900/4900 [==============================] - 7s 1ms/sample - loss: 5.0917 - f1: 0.0000e+00\n",
      "Very Positive Class performance f1: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# check class performance for very postive posts\n",
    "VNeg = train_labels[:,4] == 1\n",
    "\n",
    "\n",
    "\n",
    "scores = model.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n",
    "    train_labels[VNeg], \n",
    "                        verbose=1)\n",
    "print(\"Very Positive Class performance %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In prior modelling it was found that parent_score is an especially useful feature, this alone outperformed all other features we used when we had only used TF IDF to vectorise the text features.\n",
    "\n",
    "\n",
    "So I will build a second model which also uses parent_score in the final relu hidden layer, for this it will have to bypass the bert layer and go directly from input layer to the final hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Conv1D, Dense, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model2(max_seq_length): \n",
    "    in_id = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"input_ids\")\n",
    "    in_mask = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"input_masks\")\n",
    "    in_segment = tf.keras.layers.Input(shape=(max_seq_length*2,), name=\"segment_ids\")\n",
    "\n",
    "        \n",
    "    in_non_bert = tf.keras.layers.Input(shape=(1,), name=\"parent_score\")\n",
    "    \n",
    "    all_inputs = [in_id, in_mask, in_segment,in_non_bert]\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "\n",
    "    \n",
    "    bert_output = BertLayer(n_fine_tune_layers=3, pooling=\"first\")(bert_inputs)\n",
    "    #dense = tf.keras.layers.Dense(256, activation='relu')(bert_output)\n",
    "    merged = tf.keras.layers.concatenate([bert_output, in_non_bert])\n",
    "    dense = tf.keras.layers.Dense(42, activation='relu')( merged)\n",
    "    #pred = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
    "    pred = tf.keras.layers.Dense(5, activation='softmax')(dense)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=all_inputs , outputs=pred)\n",
    "    #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1])\n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new variable just containing all the training set parent scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_parent_scores = X_train['parent_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_parent_scores = train_parent_scores.as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the second model with combined text parent_text and Parent_score features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        [(None, 36)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_1 (BertLayer)        (None, 768)          110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "parent_score (InputLayer)       [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 769)          0           bert_layer_1[0][0]               \n",
      "                                                                 parent_score[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 42)           32340       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5)            215         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,137,445\n",
      "Trainable params: 21,886,763\n",
      "Non-trainable params: 88,250,682\n",
      "__________________________________________________________________________________________________\n",
      "384384/500000 [======================>.......] - ETA: 4:21 - loss: 0.5708 - f1: 0.7550"
     ]
    }
   ],
   "source": [
    "model2 = build_model2(max_seq_length)\n",
    "\n",
    "# Instantiate variables\n",
    "initialize_vars(sess)\n",
    "\n",
    "model2.fit(\n",
    "    [train3_input_ids, train3_input_masks, train3_segment_ids,train_parent_scores], \n",
    "    train_labels,\n",
    "   # validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=1,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000/500000 [==============================] - 740s 1ms/sample - loss: 0.4797 - f1: 0.7753\n",
      "f1: 77.53%\n"
     ]
    }
   ],
   "source": [
    "scores = model2.evaluate( [train3_input_ids, train3_input_masks, train3_segment_ids,train_parent_scores], \n",
    "    train_labels, \n",
    "                        verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm very interested in the per class performance especially for -2 and +2 as they're relatively rare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 3 arrays: [array([[ 101, 8299, 1024, ...,    0,    0,    0],\n       [ 101, 1998, 2643, ..., 7743, 1012,  102],\n       [ 101, 2017, 6579, ..., 1012, 4012,  102],\n       ...,\n       [ 101, 2054, 2785, ..., 1037, ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-fd52c7989703>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m scores = model2.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVNeg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                         verbose=1)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Very Positive Class performance %s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    344\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 3 arrays: [array([[ 101, 8299, 1024, ...,    0,    0,    0],\n       [ 101, 1998, 2643, ..., 7743, 1012,  102],\n       [ 101, 2017, 6579, ..., 1012, 4012,  102],\n       ...,\n       [ 101, 2054, 2785, ..., 1037, ..."
     ]
    }
   ],
   "source": [
    "# check class performance for very postive posts\n",
    "VNeg = train_labels[:,4] == 1\n",
    "\n",
    "\n",
    "\n",
    "scores = model2.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n",
    "    train_labels[VNeg], \n",
    "                        verbose=1)\n",
    "print(\"Very Positive Class performance %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 3 arrays: [array([[  101,  6728,  1005,  1055,  2767,  2182,  1012,  2057,  1005,\n         2128,  2183,  2000,  3477,  1037,  4284,  1997,  2009,   102,\n          101,  2027,  1005,  2128,  7079,  2005,  2009, ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-7353a67207ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m scores = model2.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mVNeg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                         verbose=1)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Very Positive Class performance %s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2649\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2651\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    344\u001b[0m                        \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                        \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                        str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 4 array(s), but instead got the following list of 3 arrays: [array([[  101,  6728,  1005,  1055,  2767,  2182,  1012,  2057,  1005,\n         2128,  2183,  2000,  3477,  1037,  4284,  1997,  2009,   102,\n          101,  2027,  1005,  2128,  7079,  2005,  2009, ..."
     ]
    }
   ],
   "source": [
    "# check class performance for very postive posts\n",
    "VNeg = train_labels[:,0] == 1\n",
    "\n",
    "\n",
    "\n",
    "scores = model2.evaluate( [train3_input_ids[VNeg], train3_input_masks[VNeg], train3_segment_ids[VNeg]], \n",
    "    train_labels[VNeg], \n",
    "                        verbose=1)\n",
    "print(\"Very Positive Class performance %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenize and create test data masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "382a1cb56783487e891d28289c333932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=1999964, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89709a84c91e4071a2a4ad49c6667551",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=1999964, style=Progress…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels \n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)\n",
    "\n",
    "(test2_input_ids, test2_input_masks, test2_segment_ids, test_labels \n",
    ") = convert_examples_to_features(tokenizer, test2_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3_input_ids = np.hstack((test_input_ids, test2_input_ids))\n",
    "test3_input_masks = np.hstack((test_input_masks, test2_input_masks))\n",
    "test3_segment_ids = np.hstack((test_segment_ids, test2_segment_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#test2_examples\n",
    "test_parent_scores = X_test['parent_score']\n",
    "test_parent_scores = test_parent_scores.as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1999964, 36)\n",
      "(1999964, 36)\n",
      "(1999964, 36)\n",
      "(1999964, 1)\n"
     ]
    }
   ],
   "source": [
    "print(test3_input_ids.shape)\n",
    "print(test3_input_masks.shape)\n",
    "print(test3_segment_ids.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalutate first model with only text features performance (this usually takes 2 hrs on a GTX 1080 level GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (1999964, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-ce700c197abc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 test3_segment_ids],\n\u001b[1;32m      4\u001b[0m                         \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         verbose=1)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2690\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2692\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    521\u001b[0m         raise ValueError('You are passing a target array of shape ' +\n\u001b[1;32m    522\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                          \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m                          \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                          \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (1999964, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "scores = model.evaluate([test3_input_ids, \n",
    "                                test3_input_masks, \n",
    "                                test3_segment_ids],\n",
    "                        test_labels, \n",
    "                        verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evalutate second model with text features and parent_score feature's performance (this usually takes 2 hrs on a GTX 1080 level GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are passing a target array of shape (1999964, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-68f18041110d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                 test3_segment_ids,test_parent_scores],\n\u001b[1;32m      4\u001b[0m                         \u001b[0mtest_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                         verbose=1)\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m         \u001b[0msteps_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'steps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2690\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2691\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2692\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2694\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    521\u001b[0m         raise ValueError('You are passing a target array of shape ' +\n\u001b[1;32m    522\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m                          \u001b[0;34m' while using as loss `categorical_crossentropy`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m                          \u001b[0;34m'`categorical_crossentropy` expects '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m                          \u001b[0;34m'targets to be binary matrices (1s and 0s) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You are passing a target array of shape (1999964, 1) while using as loss `categorical_crossentropy`. `categorical_crossentropy` expects targets to be binary matrices (1s and 0s) of shape (samples, classes). If your targets are integer classes, you can convert them to the expected format via:\n```\nfrom keras.utils import to_categorical\ny_binary = to_categorical(y_int)\n```\n\nAlternatively, you can use the loss function `sparse_categorical_crossentropy` instead, which does expect integer targets."
     ]
    }
   ],
   "source": [
    "scores2 = model2.evaluate([test3_input_ids, \n",
    "                                test3_input_masks, \n",
    "                                test3_segment_ids,test_parent_scores],\n",
    "                        test_labels, \n",
    "                        verbose=1)\n",
    "print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores2[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c5c97167caf46439c6cc792c08d6ac2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_b89a599e5f5447ab917977bad442bf35",
       "placeholder": "​",
       "style": "IPY_MODEL_e5ef06e595cc424fafec1db533661792",
       "value": "100% 500000/500000 [02:32&lt;00:00, 3285.51it/s]"
      }
     },
     "1b66066dc78d4e00abf9daf0b6557f17": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4afd3889db034c2c8af7fe39218085e4",
        "IPY_MODEL_87cfb054b9134fcc94ebaea57fd78f09"
       ],
       "layout": "IPY_MODEL_b51e4b4338be47219c53bea3078b1a91"
      }
     },
     "1ebd87d5a1834efc863382b5e3dbc22a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": "Converting examples to features",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e0aa44d5ffec4abaac0d558b41b6c8fd",
       "max": 1999964,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9eb7c6054b8a41c3abd880fb6b396778",
       "value": 193673
      }
     },
     "382a1cb56783487e891d28289c333932": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d80c4d03c13042808865fdecdbffed96",
        "IPY_MODEL_51c41634990c495f8b93448c4978f96e"
       ],
       "layout": "IPY_MODEL_d322dda2491f449eb23bc4c4376a0ede"
      }
     },
     "49614169ceb142438cd9022ea855a8fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4afd3889db034c2c8af7fe39218085e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Converting examples to features",
       "description_tooltip": null,
       "layout": "IPY_MODEL_cc875b47bb3442219ffa7901764179be",
       "max": 500000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_73a41e0caad74f48ae68cca757ad3e69",
       "value": 500000
      }
     },
     "51c41634990c495f8b93448c4978f96e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_6a81d90d25fc4f69950643ec83a78908",
       "placeholder": "​",
       "style": "IPY_MODEL_f2dcc34949d3485faf8b0af3b21f4a9a",
       "value": "100% 1999964/1999964 [10:39&lt;00:00, 3126.43it/s]"
      }
     },
     "64fa744153aa476db52bf6aadd307b6a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6a81d90d25fc4f69950643ec83a78908": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "73a41e0caad74f48ae68cca757ad3e69": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "87cfb054b9134fcc94ebaea57fd78f09": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e2cda0ad28a0413abdf0fdd37c29c13d",
       "placeholder": "​",
       "style": "IPY_MODEL_f1126fca6d31473a8439809e099cd98f",
       "value": "100% 500000/500000 [02:41&lt;00:00, 3103.52it/s]"
      }
     },
     "88ce67d7c1164a03b5c544ab2c23c799": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Converting examples to features",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e279bef545544b7b9b9088b47937e0fb",
       "max": 500000,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f96564d513d94f859dbf0b3ead55b6c1",
       "value": 500000
      }
     },
     "89709a84c91e4071a2a4ad49c6667551": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ebd87d5a1834efc863382b5e3dbc22a",
        "IPY_MODEL_e3cf62e5df7848f797ee7a5310829413"
       ],
       "layout": "IPY_MODEL_49614169ceb142438cd9022ea855a8fa"
      }
     },
     "9eb7c6054b8a41c3abd880fb6b396778": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a005c9cf23a24aa2b4326fa7596ad7a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "ab4f04e9d17145389c69d633f21963bf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "acf3d1402ace443199744cb48ccfe706": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_88ce67d7c1164a03b5c544ab2c23c799",
        "IPY_MODEL_0c5c97167caf46439c6cc792c08d6ac2"
       ],
       "layout": "IPY_MODEL_ab4f04e9d17145389c69d633f21963bf"
      }
     },
     "b51e4b4338be47219c53bea3078b1a91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b89a599e5f5447ab917977bad442bf35": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c7665d92b15245fea56556be96eec887": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "cc875b47bb3442219ffa7901764179be": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d322dda2491f449eb23bc4c4376a0ede": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d6d236731d5c4ae0b00dc383afb485da": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d80c4d03c13042808865fdecdbffed96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "IntProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "IntProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Converting examples to features",
       "description_tooltip": null,
       "layout": "IPY_MODEL_d6d236731d5c4ae0b00dc383afb485da",
       "max": 1999964,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_a005c9cf23a24aa2b4326fa7596ad7a6",
       "value": 1999964
      }
     },
     "e0aa44d5ffec4abaac0d558b41b6c8fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e279bef545544b7b9b9088b47937e0fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e2cda0ad28a0413abdf0fdd37c29c13d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e3cf62e5df7848f797ee7a5310829413": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_64fa744153aa476db52bf6aadd307b6a",
       "placeholder": "​",
       "style": "IPY_MODEL_c7665d92b15245fea56556be96eec887",
       "value": " 10% 193369/1999964 [01:04&lt;09:57, 3024.21it/s]"
      }
     },
     "e5ef06e595cc424fafec1db533661792": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f1126fca6d31473a8439809e099cd98f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f2dcc34949d3485faf8b0af3b21f4a9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "f96564d513d94f859dbf0b3ead55b6c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
